import sounddevice as sd
import numpy as np
import webrtcvad
import whisper
import queue
import collections
import time
import threading
from scipy.io.wavfile import write as write_wav

print(sd.query_devices())

# ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð°ÑƒÐ´Ð¸Ð¾
SAMPLE_RATE = 16000
FRAME_DURATION = 30  # Ð¼Ñ
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000)
BUFFER_DURATION = 1  # ÑÐµÐºÑƒÐ½Ð´
thrash_hold = 0.4

# ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð°ÑƒÐ´Ð¸Ð¾
audio_queue = queue.Queue()

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ VAD
vad = webrtcvad.Vad(0)  # Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: 0 â€” Ð½Ð°Ð¸Ð¼ÐµÐ½ÐµÐµ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Whisper Ð½Ð° GPU
print("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Whisper...")
asr_model = whisper.load_model("medium", device="cuda")
print("Whisper Ð³Ð¾Ñ‚Ð¾Ð²!")


def asr_worker(audio_data):
    timestamp = int(time.time())
    filename = f"speech_{timestamp}.wav"
    audio_np = np.frombuffer(audio_data, dtype=np.int16)
    write_wav(filename, SAMPLE_RATE, audio_np)

    print(f"ðŸ§  Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ {filename}...")
    result = asr_model.transcribe(filename)
    print(f"ðŸ“„ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {result['text']}\n")



def callback(indata, frames, time_info, status):
    audio_queue.put(bytes(indata))


def main_loop():
    ring_buffer = collections.deque(maxlen=int(BUFFER_DURATION * 1000 / FRAME_DURATION))
    triggered = False
    voiced_frames = []

    print("ðŸŽ™ ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸ (Ctrl+C Ð´Ð»Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð°)...")

    while True:
        frame = audio_queue.get()

        if not triggered:
            is_speech = vad.is_speech(frame, SAMPLE_RATE)
            ring_buffer.append(frame)
            if sum(vad.is_speech(f, SAMPLE_RATE) for f in ring_buffer) > 0.9 * ring_buffer.maxlen:
                print("ðŸŽ¤ Ð ÐµÑ‡ÑŒ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð°!")
                triggered = True
                voiced_frames.extend(ring_buffer)
                ring_buffer.clear()
        else:
            voiced_frames.append(frame)
            ring_buffer.append(frame)

            if sum(vad.is_speech(f, SAMPLE_RATE) for f in ring_buffer) < thrash_hold * ring_buffer.maxlen:
                triggered = False

                audio_bytes = b"".join(voiced_frames)
                threading.Thread(target=asr_worker, args=(audio_bytes,), daemon=True).start()

                voiced_frames = []
                ring_buffer.clear()


def run():
    with sd.RawInputStream(
        samplerate=SAMPLE_RATE,
        blocksize=FRAME_SIZE,
        dtype='int16',
        channels=1,
        callback=callback
    ):
        main_loop()


if __name__ == "__main__":
    run()
